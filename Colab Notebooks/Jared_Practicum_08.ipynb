{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Jared_Practicum_08.ipynb","provenance":[{"file_id":"1vrbIiMzGHxmlOfdbfs3UHX9hnJ8ghlcN","timestamp":1619451007563}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uuRU3M5id2wc"},"source":["## SPRING 2021\n","## Applied Machine Learning\n","### Practicum 8: Random Forest Classification."]},{"cell_type":"code","metadata":{"id":"f52oAhlS9__0"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","import matplotlib.pyplot as plt\n","\n","iris_data=load_iris()\n","iris = pd.DataFrame(data=iris_data['data'], columns=[col[:-5] for col in iris_data['feature_names']])\n","iris['target']=iris_data['target']\n","cols=['sepal length', 'sepal width', 'target']\n","iris=iris[cols]\n","\n","def plot_clf(clf):\n","  n_grid_x=200\n","  ms=0.5\n","  plt.figure(figsize=(10, 6))\n","\n","  mask_0=iris['target']==0\n","  mask_1=iris['target']==1\n","  mask_2=iris['target']==2\n","\n","  plt.plot(iris.loc[mask_0, 'sepal length'], iris.loc[mask_0, 'sepal width'], 'o', color='gold', label='setosa')\n","  plt.plot(iris.loc[mask_1, 'sepal length'], iris.loc[mask_1, 'sepal width'], 's', color='blue', label='versicolor')\n","  plt.plot(iris.loc[mask_2, 'sepal length'], iris.loc[mask_2, 'sepal width'], '^', color='green', label='virginica')\n","\n","  x_min = plt.gca().get_xlim()[0]\n","  x_max = plt.gca().get_xlim()[1]\n","  y_min = plt.gca().get_ylim()[0]\n","  y_max = plt.gca().get_ylim()[1]\n","\n","  x1 = np.linspace(x_min, x_max, n_grid_x)\n","  # The number of grid point along the vertical axis\n","  # is adjusted to have the same horizontal and vertical\n","  # spacing between the grid points \n","  n_grid_y=int(n_grid_x*y_max/x_max)\n","  x2 = np.linspace(y_min, y_max, n_grid_y)\n","\n","  # https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html\n","  x1, x2 = np.meshgrid(x1, x2)\n","  x1 = x1.reshape(n_grid_x*n_grid_y, -1)\n","  x2 = x2.reshape(n_grid_x*n_grid_y, -1)\n","\n","  x_grid=np.hstack((x1, x2))\n","\n","  y_grid = clf.predict(x_grid)\n","\n","  plt.plot(x1[y_grid==0], x2[y_grid==0], 'o', color='yellow', ms=ms)\n","  plt.plot(x1[y_grid==1], x2[y_grid==1], 'o', color='deepskyblue', ms=ms)\n","  plt.plot(x1[y_grid==2], x2[y_grid==2], 'o', color='limegreen', ms=ms)\n","\n","  plt.xlabel(\"Sepal length, cm\", fontsize=14)\n","  plt.ylabel(\"Sepal width, cm\", fontsize=14)\n","  plt.legend(#loc='lower right', \n","            fontsize=11)\n","  plt.show()\n","\n","iris.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbrDLezMd5pN"},"source":["#play with hyperparameters\n","\n","\n","\n","\n","#steps\n","#1 sanoke 80-70 percent of X train data\n","#2 build a decision tree classifier\n","#3 make predictions on X test\n","#4 predict classes or probabilities. \n","#5 repeat the process n times, where n is your favorite number and how much computing resources you have. \n","#for classifiing its majoriting voting\n","#for proabable average probablility called soft voting\n","#bragging with replacement (bootstrap) and pasting"],"execution_count":null,"outputs":[]}]}